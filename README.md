# seqToSeq-Neural-Machine-Translation

This repository contains sample code for implementing and training a deep learning-based sequence processing system. The project integrates popular machine learning libraries and frameworks to preprocess, train, and evaluate models on textual and sequential datasets.

**Features**

•PyTorch-based deep learning implementation.
•Tools and Libraries:
	1: torch for model development and training.
	2: editdistance for sequence evaluation.
	3: sentencepiece for text tokenization.
	4: wandb for experiment tracking.
•Integrates advanced text preprocessing methods and metrics for natural language processing tasks.

**Prerequisites**
	•Required Python packages: torch, editdistance, matplotlib, sacrebleu, sacremoses, sentencepiece, tqdm, wandb, and ipywidgets.
	•Install dependencies:
	pip install torch editdistance matplotlib sacrebleu sacremoses sentencepiece tqdm wandb
	pip install --upgrade jupyter ipywidgets

**Usage**

1.Installation:
	•Clone the repository and install the required packages as listed in the prerequisites.
	•Ensure your Python environment is compatible with the specified library versions.

2.Running the Code:
	•Launch the notebook in Jupyter or Google Colab.
	•Follow the steps outlined to:
	•Preprocess the dataset.
	•Train the model.
	•Evaluate performance metrics.

3.Customizing Experiments:
•Modify hyperparameters or preprocessing settings in the notebook for custom tasks.

**Acknowledgments**
	•	Author: Teja Pavan Sai Singampalli



 
